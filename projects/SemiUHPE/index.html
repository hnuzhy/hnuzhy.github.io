
<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>SemiUHPE</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <meta property="og:image" content="https://hnuzhy.github.io/projects/SemiUHPE/img/nottingham.jpg">
    <meta property="og:image:type" content="image/png">
    <meta property="og:image:width" content="1296">
    <meta property="og:image:height" content="840">
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://hnuzhy.github.io/projects/SemiUHPE/"/>
    <meta property="og:title" content="Semi-Supervised Unconstrained Head Pose Estimation in the Wild" />
    <meta property="og:description" content="Existing head pose estimation datasets are either composed of numerous samples by non-realistic synthesis or lab collection, or limited images by labor-intensive annotating. This makes deep supervised learning based solutions compromised due to the reliance on generous labeled data. To alleviate it, we propose the first semi-supervised unconstrained head pose estimation (SemiUHPE) method, which can leverage a large amount of unlabeled wild head images. Specifically, we follow the recent semi-supervised rotation regression, and focus on the diverse and complex head pose domain. Firstly, we claim that the aspect-ratio invariant cropping of heads is superior to the previous landmark-based affine alignment, which does not fit unlabeled natural heads or practical applications where landmarks are often unavailable. Then, instead of using an empirically fixed threshold to filter out pseudo labels, we propose the dynamic entropy-based filtering by updating thresholds for adaptively removing unlabeled outliers. Moreover, we revisit the design of weak-strong augmentations, and further exploit its superiority by devising two novel head-oriented strong augmentations named pose-irrelevant cut-occlusion and pose-altering rotation consistency. Extensive experiments show that SemiUHPE can surpass SOTAs with remarkable improvements on public benchmarks under both front-range and full-range."/>



<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>⚡</text></svg>">

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    
    <link rel="stylesheet" href="css/app.css">
    <link rel="stylesheet" href="css/bootstrap.min.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    
    <script src="js/app.js"></script>
    <script src="js/video_comparison.js"></script>
</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h2 class="col-md-12 text-center">
                <b>SemiUHPE</b>: Semi-Supervised Unconstrained Head Pose Estimation in the Wild</br> 
                <small>
                arXiv 2024.04 (Accepted by <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em> (<strong>TPAMI</strong>strong>) in 2025.11)
                </small></br>
                <small>
                ✅ The used Body-Head Joint Detector is our previous project <a href="https://hnuzhy.github.io/projects/BPJDet/">BPJDet</a>.
                </small></br>
                <small>
                ✅ SemiUHPE is much more superior than our previous project <a href="https://hnuzhy.github.io/projects/DirectMHP/">DirectMHP</a>.
                </small></br>
            </h2>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        <a href="https://hnuzhy.github.io">Huayi Zhou</a>
                        </br> The Chinese University of Hong Kong, Shenzhen
                    </li>
                    <li>
                        <a href="https://scholar.google.com/citations?user=EiYbuesAAAAJ&hl=en">Fei Jiang</a>
                        </br> Chongqing Academy of Science and Technology
                    </li>
                    <li>
                        <a href="https://scholar.google.com/citations?user=S1JGPCMAAAAJ&hl=en">Jin Yuan</a>
                        </br> Lenovo Research
                    </li>
                    <li><br>
                        <a href="https://scholar.google.com/citations?user=rCGsLtcAAAAJ&hl=en">Yong Rui</a>
                        </br> Lenovo Research
                    </li>
                    <li>
                        <a href="https://www.cs.sjtu.edu.cn/PeopleDetail.aspx?id=95">Hongtao Lu</a>
                        </br> Shanghai Jiao Tong University (SJTU)
                    </li>
                    <li>
                        <a href="http://kuijia.site/">Kui Jia</a>
                        </br> The Chinese University of Hong Kong, Shenzhen
                    </li>
                </ul>
            </div>
        </div>


        <div class="row">
                <div class="col-md-6 col-md-offset-3 text-center">
                    <ul class="nav nav-pills nav-justified">
                        <li>
                            <a href="https://arxiv.org/abs/2404.02544">
                            <image src="img/SemiUHPE_image.jpg" height="40px">
                                <h4><strong>arXiv</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a href="https://github.com/hnuzhy/SemiUHPE">
                            <image src="img/github.png" height="40px">
                                <h4><strong>Code</strong></h4>
                            </a>
                        </li>
                    </ul>
                </div>
        </div>


        <div class="row">
    		<div class="col-md-8 col-md-offset-2">
                <image src="img/teaser_image.png" class="img-responsive" alt="overview"><br>
		<p class="text-justify">
			The unconstrained head pose estimation results of our SemiUHPE on wild challenging heads (e.g., heavy blur, extreme illumination, severe occlusion, atypical pose, and invisible face).
		</p>
                <video id="v0" width="100%" autoplay loop muted controls>
                  <source src="img/teaser_video.mp4" type="video/mp4" />
                </video>
		<table style="width: 100%; border-collapse: collapse;">
		  	<tr>
			    <td style="text-align: center;">
			<video id="v0" width="100%" autoplay loop muted>
			  <source src="img/test1_BPJDetSemiUHPE.mp4" type="video/mp4" />
			</video>
				</td>
 			 <td style="text-align: center;">
			<video id="v0" width="100%" autoplay loop muted>
			  <source src="img/test2_BPJDetSemiUHPE.mp4" type="video/mp4" />
			</video>
			</td>
  			<td style="text-align: center;">
			<video id="v0" width="100%" autoplay loop muted>
			  <source src="img/test3_BPJDetSemiUHPE.mp4" type="video/mp4" />
			</video>
			</td>
		  	</tr>
		  	<tr>
			    <td style="text-align: center;">Short Phone Video 1</td>
			    <td style="text-align: center;">Short Phone Video 2</td>
			    <td style="text-align: center;">Short Phone Video 3</td>
		  	</tr>
		</table>
		</div>
        </div>


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <image src="img/framework.png" class="img-responsive" alt="overview"><br>
                <p class="text-justify">
Existing research on unconstrained in-the-wild head pose estimation suffers from the flaws of its datasets, which consist of either numerous samples by non-realistic synthesis or constrained collection, or small-scale natural images yet with plausible manual annotations. To alleviate it, we propose the first semi-supervised unconstrained head pose estimation method SemiUHPE, which can leverage abundant easily available unlabeled head images. Technically, we choose semi-supervised rotation regression and adapt it to the error-sensitive and label-scarce problem of unconstrained head pose. Our method is based on the observation that the aspect-ratio invariant cropping of wild heads is superior to the previous landmark-based affine alignment given that landmarks of unconstrained human heads are usually unavailable, especially for less-explored non-frontal heads. Instead of using an empirically fixed threshold to filter out pseudo labeled heads, we propose dynamic entropy based filtering to adaptively remove unlabeled outliers as training progresses by updating the threshold in multiple stages. We then revisit the design of weak-strong augmentations and improve it by devising two novel head-oriented strong augmentations, termed pose-irrelevant cut-occlusion and pose-altering rotation consistency respectively. Extensive experiments and ablation studies show that SemiUHPE outperforms existing methods greatly on public benchmarks under both the front-range and full-range settings.
                </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    SemiUHPE vs. previous SOTAs
                </h3>
                <image src="img/ComparingNew.png" class="img-responsive" alt="overview"><br>
                <p class="text-justify">
                    Visualizations of front-range or full-range head pose estimation (HPE). Our method SemiUHPE is more robust to severe occlusion, atypical pose and invisible face.
                </p>
                <image src="img/ComparingDAD3DHeads.png" class="img-responsive" alt="overview"><br>
                <p class="text-justify">
                    Qualitative results of our method (<em>3rd line</em>) and DAD-3DNet (<em>2nd line</em>) on heads from DAD-3DHeads test-set (<em>1st line</em>), which never appeared during SSL training.
                </p>
            </div>
        </div>

<br>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    More Quantitative Results of SemiUHPE
                </h3>
                <video id="v0" width="100%" autoplay loop muted controls>
                  <source src="img/Classroom_BPJDetSemiUHPE.mp4" type="video/mp4" />
                </video>
                <p class="text-justify">Real Classrooms.</p>
              
                <video id="v0" width="100%" autoplay loop muted controls>
                  <source src="img/CaiXukun_Self-Intro_BPJDet+SemiUHPE_audio.mp4" type="video/mp4" />
                </video>
                <p class="text-justify">Recorded Vlogs.</p>

                <table style="width: 100%; border-collapse: collapse;">
                  <tr>
                    <td style="text-align: center;">
                        <image src="application/273271,2277e000891f2e71.jpg" width=97% class="img-responsive" alt="overview">
                    </td>
                    <td style="text-align: center;">
                        <image src="application/273271,2277e000891f2e71_res_BPJDetSemiUHPE.jpg" width=97% class="img-responsive" alt="overview">
                    </td>
                  </tr>
                </table>
                <table style="width: 100%; border-collapse: collapse;">
                  <tr>
                    <td style="text-align: center;">
                        <image src="application/273275,a02c9000bdd4821a.jpg" width=97% class="img-responsive" alt="overview">
                    </td>
                    <td style="text-align: center;">
                        <image src="application/273275,a02c9000bdd4821a_res_BPJDetSemiUHPE.jpg" width=97% class="img-responsive" alt="overview">
                    </td>
                  </tr>
                </table>
                <table style="width: 100%; border-collapse: collapse;">
                  <tr>
                    <td style="text-align: center;">
                        <image src="application/284193,1bc1600091115174.jpg" width=97% class="img-responsive" alt="overview">
                    </td>
                    <td style="text-align: center;">
                        <image src="application/284193,1bc1600091115174_res_BPJDetSemiUHPE.jpg" width=97% class="img-responsive" alt="overview">
                    </td>
                  </tr>
                </table>
                <table style="width: 100%; border-collapse: collapse;">
                  <tr>
                    <td style="text-align: center;">
                        <image src="application/284193,29047000aedddc9d.jpg" width=97% class="img-responsive" alt="overview">
                    </td>
                    <td style="text-align: center;">
                        <image src="application/284193,29047000aedddc9d_res_BPJDetSemiUHPE.jpg" width=97% class="img-responsive" alt="overview">
                    </td>
                  </tr>
                </table>
                <table style="width: 100%; border-collapse: collapse;">
                  <tr>
                    <td style="text-align: center;">
                        <image src="application/PartB_00009.jpg" width=97% class="img-responsive" alt="overview">
                    </td>
                    <td style="text-align: center;">
                        <image src="application/PartB_00009_res_BPJDetSemiUHPE.jpg" width=97% class="img-responsive" alt="overview">
                    </td>
                  </tr>
                </table>
                <table style="width: 100%; border-collapse: collapse;">
                  <tr>
                    <td style="text-align: center;">
                        <image src="application/PartB_00167.jpg" width=97% class="img-responsive" alt="overview">
                    </td>
                    <td style="text-align: center;">
                        <image src="application/PartB_00167_res_BPJDetSemiUHPE.jpg" width=97% class="img-responsive" alt="overview">
                    </td>
                  </tr>
                </table>
                <table style="width: 100%; border-collapse: collapse;">
                  <tr>
                    <td style="text-align: center;">
                        <image src="application/PartB_00351.jpg" width=97% class="img-responsive" alt="overview">
                    </td>
                    <td style="text-align: center;">
                        <image src="application/PartB_00351_res_BPJDetSemiUHPE.jpg" width=97% class="img-responsive" alt="overview">
                    </td>
                  </tr>
                </table>
                <table style="width: 100%; border-collapse: collapse;">
                  <tr>
                    <td style="text-align: center;">
                        <image src="application/PartB_02161.jpg" width=97% class="img-responsive" alt="overview">
                    </td>
                    <td style="text-align: center;">
                        <image src="application/PartB_02161_res_BPJDetSemiUHPE.jpg" width=97% class="img-responsive" alt="overview">
                    </td>
                  </tr>
                </table>
		<p class="text-justify">Many in-the-wild images with multiple persons.</p>
		    
            </div>
        </div>

			
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Citation
                </h3>
                <div class="form-group col-md-10 col-md-offset-1">
                    <textarea id="bibtex" class="form-control" readonly>
@article{zhou2024semi,
  title={Semi-Supervised Unconstrained Head Pose Estimation in the Wild},
  author={Zhou, Huayi and Jiang, Fei and Jin, Yuan and Yong, Rui and Lu, Hongtao and Kui, Jia},
  journal={arXiv preprint arXiv:2404.02544},
  year={2024}
}
@article{zhou2024bpjdet,
  title={BPJDet: Extended Object Representation for Generic Body-Part Joint Detection},
  author={Zhou, Huayi and Jiang, Fei and Si, Jiaxin and Ding, Yue and Lu, Hongtao},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2024},
  publisher={IEEE}
}
@inproceedings{zhou2023body,
  title={Body-part joint detection and association via extended object representation},
  author={Zhou, Huayi and Jiang, Fei and Lu, Hongtao},
  booktitle={2023 IEEE International Conference on Multimedia and Expo (ICME)},
  pages={168--173},
  year={2023},
  organization={IEEE}
}      
                    </textarea>
                </div>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Acknowledgements
                </h3>
                <p class="text-justify">
                We acknowledge the effort from authors of human-related datasets including <a href="https://www.crowdhuman.org/">CrowdHuman</a>, <a href="https://github.com/soeaver/Hier-R-CNN">COCOHumanParts</a> and <a href="https://www.pinatafarm.com/research/dad-3dheads">DAD-3DHeads</a>. These datasets make researches and downstream applications about <em>Semi-Supervised Unconstrained Head Pose Estimation in the Wild</em> possible. 
                    <br><br>
                The website template was borrowed from <a href="https://jonbarron.info/">Jon Barron</a> and <a href="https://jonbarron.info/zipnerf/">Zip-NeRF</a>.
                </p>
            </div>
        </div>
    </div>
</body>
</html>
