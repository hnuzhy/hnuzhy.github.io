
<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>SemiUHPE</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <meta property="og:image" content="https://hnuzhy.github.io/projects/SemiUHPE/img/nottingham.jpg">
    <meta property="og:image:type" content="image/png">
    <meta property="og:image:width" content="1296">
    <meta property="og:image:height" content="840">
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://hnuzhy.github.io/projects/SemiUHPE/"/>
    <meta property="og:title" content="Semi-Supervised Unconstrained Head Pose Estimation in the Wild" />
    <meta property="og:description" content="Existing head pose estimation datasets are either composed of numerous samples by non-realistic synthesis or lab collection, or limited images by labor-intensive annotating. This makes deep supervised learning based solutions compromised due to the reliance on generous labeled data. To alleviate it, we propose the first semi-supervised unconstrained head pose estimation (SemiUHPE) method, which can leverage a large amount of unlabeled wild head images. Specifically, we follow the recent semi-supervised rotation regression, and focus on the diverse and complex head pose domain. Firstly, we claim that the aspect-ratio invariant cropping of heads is superior to the previous landmark-based affine alignment, which does not fit unlabeled natural heads or practical applications where landmarks are often unavailable. Then, instead of using an empirically fixed threshold to filter out pseudo labels, we propose the dynamic entropy-based filtering by updating thresholds for adaptively removing unlabeled outliers. Moreover, we revisit the design of weak-strong augmentations, and further exploit its superiority by devising two novel head-oriented strong augmentations named pose-irrelevant cut-occlusion and pose-altering rotation consistency. Extensive experiments show that SemiUHPE can surpass SOTAs with remarkable improvements on public benchmarks under both front-range and full-range."/>



<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>âš¡</text></svg>">

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    
    <link rel="stylesheet" href="css/app.css">
    <link rel="stylesheet" href="css/bootstrap.min.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    
    <script src="js/app.js"></script>
    <script src="js/video_comparison.js"></script>
</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h2 class="col-md-12 text-center">
                <b>SemiUHPE</b>: Semi-Supervised Unconstrained Head Pose Estimation in the Wild</br> 
                <small>
                arXiv 2024.04 (under review)
                </small></br>
            </h2>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        <a href="https://hnuzhy.github.io">Huayi Zhou</a>
                        </br>Shanghai Jiao Tong University (SJTU)
                    </li>
                    <li>
                        <a href="https://scholar.google.com/citations?user=EiYbuesAAAAJ&hl=en">Fei Jiang</a>
                        </br>Chongqing Academy of Science and Technology
                    </li>
                    <li>
                        <a href="https://www.cs.sjtu.edu.cn/PeopleDetail.aspx?id=95">Hongtao Lu</a>
                        </br> Shanghai Jiao Tong University (SJTU)
                    </li>
                </ul>
            </div>
        </div>


        <div class="row">
                <div class="col-md-5 col-md-offset-3 text-center">
                    <ul class="nav nav-pills nav-justified">
                        <li>
                            <a href="https://arxiv.org/abs/2404.xxxxx">
                            <image src="img/SemiUHPE_image.jpg" height="40px">
                                <h4><strong>arXiv</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a href="https://github.com/hnuzhy/SemiUHPE">
                            <image src="img/github.png" height="40px">
                                <h4><strong>Code</strong></h4>
                            </a>
                        </li>
                    </ul>
                </div>
        </div>


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <image src="img/teaser_image.png" class="img-responsive" alt="overview"><br>
		<p class="text-justify">
			The unconstrained head pose estimation results of our SemiUHPE on wild challenging heads (e.g., heavy blur, extreme illumination, severe occlusion, atypical pose, and invisible face).
		</p>
                <video id="v0" width="100%" autoplay loop muted controls>
                  <source src="img/teaser_video.mp4" type="video/mp4" />
                </video>
	          </div>
        </div>


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <image src="img/framework.png" class="img-responsive" alt="overview"><br>
                <p class="text-justify">
Existing head pose estimation datasets are either composed of numerous samples by non-realistic synthesis or lab collection, or limited images by labor-intensive annotating. This makes deep supervised learning based solutions compromised due to the reliance on generous labeled data. To alleviate it, we propose the first semi-supervised unconstrained head pose estimation (SemiUHPE) method, which can leverage a large amount of unlabeled wild head images. Specifically, we follow the recent semi-supervised rotation regression, and focus on the diverse and complex head pose domain. Firstly, we claim that the aspect-ratio invariant cropping of heads is superior to the previous landmark-based affine alignment, which does not fit unlabeled natural heads or practical applications where landmarks are often unavailable. Then, instead of using an empirically fixed threshold to filter out pseudo labels, we propose the dynamic entropy-based filtering by updating thresholds for adaptively removing unlabeled outliers. Moreover, we revisit the design of weak-strong augmentations, and further exploit its superiority by devising two novel head-oriented strong augmentations named pose-irrelevant cut-occlusion and pose-altering rotation consistency. Extensive experiments show that SemiUHPE can surpass SOTAs with remarkable improvements on public benchmarks under both front-range and full-range.
                </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    SemiUHPE vs. previous SOTAs
                </h3>
                <image src="img/ComparingNew.png" class="img-responsive" alt="overview"><br>
                <p class="text-justify">
                    Visualizations of front-range or full-range head pose estimation (HPE). Our method SemiUHPE is more robust to severe occlusion, atypical pose and invisible face.
                </p>
                <image src="img/ComparingDAD3DHeads.png" class="img-responsive" alt="overview"><br>
                <p class="text-justify">
                    Qualitative results of our method (<em>1st line</em>) and DAD-3DNet (<em>2nd line</em>) on heads from DAD-3DHeads test-set, which never appeared during SSL training.
                </p>
            </div>
        </div>

<br>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    More Quantitative Results of SemiUHPE
                </h3>
                <video id="v0" width="100%" autoplay loop muted controls>
                  <source src="img/Classroom_BPJDet+SemiUHPE.mp4" type="video/mp4" />
                </video>
                <p class="text-justify">Real Classrooms.</p>
              
                <video id="v0" width="100%" autoplay loop muted controls>
                  <source src="img/CaiXukun_Self-Intro_BPJDet+SemiUHPE_audio.mp4" type="video/mp4" />
                </video>
                <p class="text-justify">Recorded Vlogs.</p>

        				<table style="width: 100%; border-collapse: collapse;">
        				  <tr>
        				    <td style="text-align: center;">
        		                <video id="v0" width="100%" autoplay loop muted>
        		                  <source src="img/test1_BPJDet+SemiUHPE.mp4" type="video/mp4" />
        		                </video>
        					</td>
                  <td style="text-align: center;">
        		                <video id="v0" width="100%" autoplay loop muted>
        		                  <source src="img/test2_BPJDet+SemiUHPE.mp4" type="video/mp4" />
        		                </video>
        					</td>
                  <td style="text-align: center;">
        		                <video id="v0" width="100%" autoplay loop muted>
        		                  <source src="img/test3_BPJDet+SemiUHPE.mp4" type="video/mp4" />
        		                </video>
        					</td>
        				  </tr>
        				  <tr>
        				    <td style="text-align: center;">Short Phone Video 1</td>
        				    <td style="text-align: center;">Short Phone Video 2</td>
                    <td style="text-align: center;">Short Phone Video 3</td>
        				  </tr>
        				</table>
              
            </div>
        </div>


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Citation
                </h3>
                <div class="form-group col-md-10 col-md-offset-1">
                    <textarea id="bibtex" class="form-control" readonly>
@article{zhou2024semi,
  title={Semi-Supervised Unconstrained Head Pose Estimation in the Wild},
  author={Zhou, Huayi and Jiang, Fei and Lu, Hongtao},
  journal={arXiv preprint arXiv:2404.xxxxx},
  year={2024}
}
                      
                    </textarea>
                </div>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Acknowledgements
                </h3>
                <p class="text-justify">
                We acknowledge the effort from authors of human-related datasets including <a href="https://www.crowdhuman.org/">CrowdHuman</a>, <a href="https://github.com/soeaver/Hier-R-CNN">COCOHumanParts</a> and <a href="https://www.pinatafarm.com/research/dad-3dheads">DAD-3DHeads</a>. These datasets make researches and downstream applications about <em>Semi-Supervised Unconstrained Head Pose Estimation in the Wild</em>em possible. 
                    <br><br>
                The website template was borrowed from <a href="https://jonbarron.info/">Jon Barron</a> and <a href="https://jonbarron.info/zipnerf/">Zip-NeRF</a>.
                </p>
            </div>
        </div>
    </div>
</body>
</html>
